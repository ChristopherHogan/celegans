d10x.data <- lapply(ids, function(i) {
data <- Read10X(data.dir = file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix"))
})
d10x.data
glimpse(d10x.data)
library(tidyverse)
glimpse(d10x.data)
glimpse(d10x.data[1])
d10x.data[1]$Dimnames
d10x.data[1]@Dimnames
d10x.data[1]
typeof(d10x.data[1])
typeof(d10x.data[1][1])
typeof(d10x.data[1][1][1])
typeof(d10x.data)
typeof(d10x.data[1])
D10X.DATA[1]
d10x.data[1]
names(d10x.data) <- ids
sobject.list <- lapply(ids, function(i) {
sobject <- CreateSeuratObject(counts = d10x.data[[i]])
# remember which id the data belongs to (useful after integration)
sobject[["group"]] <- rep(i, times = length(sobject@meta.data$nCount_RNA))
# Does the 'MT' prefix signify mitochondrial DNA in C. elegans and does it need to be filtered out?
sobject[["percent.mt"]] <- PercentageFeatureSet(sobject, pattern = "^MT")
sobject
})
names(sobject.list) <- ids
help(Matrix::dgCMatrix)
help(Matrix)
help(dgcMatrix)
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
experiment_name <- "C. elegans scRNA-seq"
dataset_loc <- "../ackley_data"
ids <- c("GABA1", "GABA2")
d10x.data <- lapply(ids, function(i) {
data <- Read10X(data.dir = file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix"))
})
df <- as.data.frame(as.matrix(d10x.data[1]))
glimpse(df)
library(tidyverse)
glimpse(df)
df <- as.data.frame(as.matrix(d10x.data[1]['assays']['RNA']['data']))
df
library(nycflights13)
flights |> mutate(gain = dep_delay - arr_delay, speed = distance / air_time * 60)
View(flights |> mutate(gain = dep_delay - arr_delay, speed = distance / air_time * 60))
flights |> select(year, month, day)
flights |> select(year:day)
flights |> select(!year:day)
flights |> select(where(is.character))
flights |> select(sched_dep_time)
flights |> select(sched_dep_time) |> filter(matches("^6"))
flights |> select(contains("TIME"))
flights |> select(contains("time"))
flights |> select(contains("TIME", ignore.case = FALSE))
flights |> select(tailnum)
flights |> group_by(month)
View(flights |> group_by(month))
flights |> group_by(month) |> summarize(avg_delay = mean(dep_delay))
flights |> group_by(month) |> summarize(avg_delay = mean(dep_delay, na.rm = TRUE))
flights summarize(avg_delay = mean(dep_delay, na.rm = TRUE))
flights summarize(avg_delay = mean(dep_delay, na.rm = TRUE)
flights |>  summarize(avg_delay = mean(dep_delay, na.rm = TRUE)
)
flights
flights |> group_by(month) |> summarize(delay = mean(dep_delay, na.rm = TRUE), n = n())
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
experiment_name <- "C. elegans scRNA-seq"
dataset_loc <- "../ackley_data"
ids <- c("GABA1", "GABA2")
d10x.data <- lapply(ids, function(i) {
#  data <- Read10X(data.dir = file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix"))
data <- Read10X_h5(data.dir = file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix.h5"))
})
d10x.data <- lapply(ids, function(i) {
#  data <- Read10X(data.dir = file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix"))
data <- Read10X_h5(file.path(dataset_loc, i, "outs", "filtered_feature_bc_matrix.h5"))
})
names(d10x.data) <- ids
sobject.list <- lapply(ids, function(i) {
sobject <- CreateSeuratObject(counts = d10x.data[[i]])
# remember which id the data belongs to (useful after integration)
sobject[["group"]] <- rep(i, times = length(sobject@meta.data$nCount_RNA))
# Does the 'MT' prefix signify mitochondrial DNA in C. elegans and does it need to be filtered out?
sobject[["percent.mt"]] <- PercentageFeatureSet(sobject, pattern = "^MT")
sobject
})
names(sobject.list) <- ids
# normalize and identify variable features for each dataset independently
sobject.list <- lapply(X = sobject.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
# select features that are repeatedly variable across datasets for integration
features <- SelectIntegrationFeatures(object.list = sobject.list)
grouped.anchors <- FindIntegrationAnchors(object.list = sobject.list, anchor.features = features)
# this command creates an 'integrated' data assay
grouped.combined <- IntegrateData(anchorset = grouped.anchors)
# specify that we will perform downstream analysis on the corrected data
# note that the original unmodified data still resides in the 'RNA' assay
DefaultAssay(grouped.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
grouped.combined <- ScaleData(grouped.combined, verbose = FALSE)
grouped.combined <- RunPCA(grouped.combined, npcs = 30, verbose = FALSE)
grouped.combined <- RunPCA(grouped.combined, npcs = 30, verbose = FALSE)
grouped.combined <- RunUMAP(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- RunPCA(grouped.combined, npcs = 30, verbose = FALSE)
grouped.combined <- RunUMAP(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindNeighbors(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindClusters(grouped.combined, resolution = 0.5)
# Visualization
p1 <- DimPlot(grouped.combined, reduction = "umap", group.by = 'group')
p2 <- DimPlot(grouped.combined, reduction = "umap", label = TRUE, repel = TRUE)
p1 + p2
# For performing differential expression after integration, we switch back to the original data
DefaultAssay(grouped.combined) <- "RNA"
nk.markers <- FindConservedMarkers(grouped.combined, ident.1 = 6, grouping.var = "group", verbose = FALSE)
nk.markers <- FindConservedMarkers(grouped.combined, ident.1 = 6, grouping.var = "group", verbose = FALSE)
head(nk.markers)
head(d10x.data[1:10, 1:10])
head(d10x.data[1, 1:10, 1:10])
head(d10x.data[1][1:10, 1:10])
head(d10x.data[1])
head(d10x.data[2])
df1 <- as.data.fram(as.matrix(d10x.data[1]))
df1 <- as.data.frame(as.matrix(d10x.data[1]))
df2 <- as.data.frame(as.matrix(d10x.data[2]))
df1
d10x.data[1]
df1 <- as.data.frame(as.matrix(d10x.data[[1]]))
df1
View(df1)
df2 <- as.data.frame(as.matrix(d10x.data[[2]]))
glimpse(df1)
d10x.data
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
plots <- lapply(ids, function(i) {
plot1 <- VariableFeaturePlot(sobject.list[[i]]) + labs(title = i)
plot2 <- LabelPoints(plot = plot1, points = top10[[i]], repel = TRUE)
plot2
})
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
experiment_name <- "C. elegans scRNA-seq"
dataset_loc <- "../ackley_data"
ids <- c("GABA1", "GABA2")
d10x.data <- lapply(ids, function(i) {
data <- Read10X_h5(file.path(dataset_loc, i, "outs",
"filtered_feature_bc_matrix.h5"))
})
names(d10x.data) <- ids
sobject.list <- lapply(ids, function(i) {
sobject <- CreateSeuratObject(counts = d10x.data[[i]], project = i)
# remember which id the data belongs to (useful after integration)
sobject[["group"]] <- rep(i, times = length(sobject@meta.data$nCount_RNA))
# This data appears to be already filtered. The highest percent.mt value
# is 2%.
sobject[["percent.mt"]] <- PercentageFeatureSet(sobject, pattern = "^MT")
sobject
})
names(sobject.list) <- ids
# normalize and identify variable features for each dataset independently
sobject.list <- lapply(X = sobject.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
# Identify the 10 most highly variable genes
top10 <- lapply(ids, function(i) {
head(VariableFeatures(sobject.list[[i]]), 10)
})
plots = list()
for (i in ids) {
plot1 <- VariableFeaturePlot(sobject.list[[i]]) + labs(title = i)
plot2 <- LabelPoints(plot = plot1, points = top10[[i]], repel = TRUE)
plots[[i]] = plot2
}
library(tidyverse)
for (i in ids) {
plot1 <- VariableFeaturePlot(sobject.list[[i]]) + labs(title = i)
plot2 <- LabelPoints(plot = plot1, points = top10[[i]], repel = TRUE)
plots[[i]] = plot2
}
plots[[1]] + plots[[2]]
plots[[1]]
plots
plots = list()
for (i in c("GABA1")) {
plot1 <- VariableFeaturePlot(sobject.list[[i]]) + labs(title = i)
plot2 <- LabelPoints(plot = plot1, points = top10[[i]], repel = TRUE)
plots[[i]] = plot2
}
plots[[1]]
top10
names(top10) <- ids
top10
features
# select features that are repeatedly variable across datasets for integration
features <- SelectIntegrationFeatures(object.list = sobject.list)
features
head(features, n = 10)
head(features, n = 25)
top10
head(features, n = 25)
grouped.combined
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
experiment_name <- "C. elegans scRNA-seq"
dataset_loc <- "../ackley_data"
ids <- c("GABA1", "GABA2")
d10x.data <- lapply(ids, function(i) {
data <- Read10X_h5(file.path(dataset_loc, i, "outs",
"filtered_feature_bc_matrix.h5"))
})
names(d10x.data) <- ids
sobject.list <- lapply(ids, function(i) {
sobject <- CreateSeuratObject(counts = d10x.data[[i]], project = i)
# remember which id the data belongs to (useful after integration)
sobject[["group"]] <- rep(i, times = length(sobject@meta.data$nCount_RNA))
# This data appears to be already filtered. The highest percent.mt value
# is 2%.
sobject[["percent.mt"]] <- PercentageFeatureSet(sobject, pattern = "^MT")
sobject
})
names(sobject.list) <- ids
# normalize and identify variable features for each dataset independently
sobject.list <- lapply(X = sobject.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
top10 <- lapply(ids, function(i) {
head(VariableFeatures(sobject.list[[i]]), 10)
})
names(top10) <- ids
top10
features <- SelectIntegrationFeatures(object.list = sobject.list)
head(features, n = 25)
grouped.anchors <- FindIntegrationAnchors(object.list = sobject.list, anchor.features = features)
# this command creates an 'integrated' data assay
grouped.combined <- IntegrateData(anchorset = grouped.anchors)
# specify that we will perform downstream analysis on the corrected data
# note that the original unmodified data still resides in the 'RNA' assay
DefaultAssay(grouped.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
grouped.combined <- ScaleData(grouped.combined, verbose = FALSE)
grouped.combined <- RunPCA(grouped.combined, npcs = 30, verbose = FALSE)
grouped.combined <- RunUMAP(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindNeighbors(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindClusters(grouped.combined, resolution = 0.5)
# Visualization
p1 <- DimPlot(grouped.combined, reduction = "umap", group.by = 'group')
p2 <- DimPlot(grouped.combined, reduction = "umap", label = TRUE, repel = TRUE)
p1 + p2
DimPlot(grouped.combined, reduction = "umap", split.by = "group")
grouped.combined
View(grouped.combined)
# For performing differential expression after integration, we switch back to the original data
DefaultAssay(grouped.combined) <- "RNA"
# For performing differential expression after integration, we switch back to the original data
DefaultAssay(grouped.combined) <- "RNA"
nk.markers <- FindConservedMarkers(grouped.combined, ident.1 = 0, grouping.var = "group", verbose = FALSE)
head(nk.markers, n = 25)
DimPlot(grouped.combined, reduction = "umap", split.by = "group", label = TRUE)
markers
markers <- FindConservedMarkers(grouped.combined, ident.1 = 0,
grouping.var = "group", verbose = FALSE)
markers
mdf <- as.data.frame(markers)
mdf
glimpse(mdf)
mdf[0:25,]
mdf[0:25,]
mdf[0:25,]
write.csv(mdf[0:25,], "./pc0.csv", row.names = TRUE)
for (i in 0:1) {
markers <- FindConservedMarkers(grouped.combined, ident.1 = i,
grouping.var = "group", verbose = FALSE)
df <- as.data.frame(markers)
write.csv(df[0:25,], sprintf("./csv/pc%d.csv", i), row.names = TRUE)
}
for (i in 0:19) {
markers <- FindConservedMarkers(grouped.combined, ident.1 = i,
grouping.var = "group", verbose = FALSE)
df <- as.data.frame(markers)
write.csv(df[0:25,], sprintf("./csv/pc%d.csv", i), row.names = TRUE)
}
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
experiment_name <- "C. elegans scRNA-seq"
dataset_loc <- "../ackley_data"
ids <- c("GABA1", "GABA2")
d10x.data <- lapply(ids, function(i) {
data <- Read10X_h5(file.path(dataset_loc, i, "outs",
"filtered_feature_bc_matrix.h5"))
})
names(d10x.data) <- ids
sobject.list <- lapply(ids, function(i) {
sobject <- CreateSeuratObject(counts = d10x.data[[i]], project = i)
# remember which id the data belongs to (useful after integration)
sobject[["group"]] <- rep(i, times = length(sobject@meta.data$nCount_RNA))
# This data appears to be already filtered. The highest percent.mt value
# is 2%.
sobject[["percent.mt"]] <- PercentageFeatureSet(sobject, pattern = "^MT")
sobject
})
names(sobject.list) <- ids
# normalize and identify variable features for each dataset independently
sobject.list <- lapply(X = sobject.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
top10 <- lapply(ids, function(i) {
head(VariableFeatures(sobject.list[[i]]), 10)
})
names(top10) <- ids
top10
features <- SelectIntegrationFeatures(object.list = sobject.list)
head(features, n = 25)
grouped.anchors <- FindIntegrationAnchors(object.list = sobject.list, anchor.features = features)
# this command creates an 'integrated' data assay
grouped.combined <- IntegrateData(anchorset = grouped.anchors)
# specify that we will perform downstream analysis on the corrected data
# note that the original unmodified data still resides in the 'RNA' assay
DefaultAssay(grouped.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
grouped.combined <- ScaleData(grouped.combined, verbose = FALSE)
grouped.combined <- RunPCA(grouped.combined, npcs = 30, verbose = FALSE)
grouped.combined <- RunUMAP(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindNeighbors(grouped.combined, reduction = "pca", dims = 1:30)
grouped.combined <- FindClusters(grouped.combined, resolution = 0.5)
# Visualization
p1 <- DimPlot(grouped.combined, reduction = "umap", group.by = 'group')
p2 <- DimPlot(grouped.combined, reduction = "umap", label = TRUE, repel = TRUE)
p1 + p2
DimPlot(grouped.combined, reduction = "umap", split.by = "group", label = TRUE)
grouped.combined[["pca"]]
print(grouped.combined[["pca"]], dims = 1:5, nfeatures = 5)
print(grouped.combined[["pca"]], dims = 1:5, nfeatures = 19)
print(grouped.combined[["pca"]], dims = 1:19, nfeatures = 5)
DimHeatmap(grouped.combined, dims = 1, cells = 500, balanced = TRUE)
DimHeatmap(grouped.combined, dims = 1:19, cells = 500, balanced = TRUE)
required_packages <- c("BiocManager",
"shiny", "shinyjs", "shinythemes", "shinybusy",
"DT", "tidyverse", "pheatmap","ggridges", "cowplot",
"plotly","expss", "xlsx", "qs")
install.packages(required_packages)
BiocManager::install(c("limma", "edgeR"))
Sys.getenv("OneDrive")
x = 'hi'
paste(x, "_bye")
paste(x, "_bye", sep='')
remove(x)
all_times <- list()  # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
now <<- Sys.time()
} else {
res <- difftime(Sys.time(), now, units = "secs")
all_times[[options$label]] <<- res
}
}
}))
knitr::opts_chunk$set(
tidy = TRUE,
tidy.opts = list(width.cutoff = 95),
fig.width = 10,
message = FALSE,
warning = FALSE,
time_it = TRUE
)
library(Seurat)
library(patchwork)
```{r imports}
library(Seurat)
library(patchwork)
library(Seurat)
library(patchwork)
experiment_name <- "cholinergic" # or "gaba"
one_drive <- gsub("\\\\", "/", Sys.getenv("OneDrive"))
data_dir <- paste(experiment_name, "_data", sep = "")
data_dir_path <- file.path(one_drive, "research", data_dir)
# TODO: uncomment when dataset 2 is ready
ids <- c("1") #, "2")
d10x.data <- lapply(ids, function(i) {
file_name <- paste(experiment_name, i, "_filtered_feature_bc_matrix.h5")
data <- Read10X_h5(file.path(data_dir_path, file_name))
})
View(all_times)
source("~/.active-rstudio-document", echo=TRUE)
